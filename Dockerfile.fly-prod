# ArcticCodex Full Stack - Fly.io Production
# Runs Studio Server with Vault + LLM inference

FROM python:3.12-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PYTHONPATH=/app \
    PORT=8000 \
    AC_EMBEDDINGS=1 \
    AC_EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

WORKDIR /app

# System dependencies for ML inference
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    git \
    libopenblas-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --upgrade pip setuptools wheel && \
    pip install -r requirements.txt

# Try to install optional ML packages (non-blocking)
RUN pip install --no-error --upgrade \
    sentence-transformers \
    llama-cpp-python \
    2>/dev/null || true

# Copy application code
COPY packages ./packages
COPY ForgeNumerics_Language ./ForgeNumerics_Language
COPY start_fly_server.py ./start_fly_server.py

# Create persistent mount points (consolidated into /app/data for Fly.io single volume)
RUN mkdir -p /app/data/vault /app/data/models /app/cache && \
    chmod -R 755 /app

EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 --start-period=40s \
    CMD curl -f http://localhost:8000/api/health || exit 1

# Run Studio Server via startup wrapper with error handling
CMD ["python", "start_fly_server.py"]
